{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMYGjT479WRaqRG+3YVSwNc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benryanx/skin-cancer-detection-ai/blob/main/Skin_Cancer_Detection_ResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this project, I will use the HAM10000 dataset (\"Human Against Machine with 10,000 images\"),\n",
        "which is the industry benchmark for skin lesion classification."
      ],
      "metadata": {
        "id": "JLKoPpc2qnTg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Ingestion & Setup"
      ],
      "metadata": {
        "id": "VlUUGREXYGmt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04iW4oELqcfh"
      },
      "outputs": [],
      "source": [
        "# --- STEP A: SETUP KAGGLE & DOWNLOAD DATA ---\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Upload your kaggle.json here\n",
        "if not os.path.exists(\"/root/.kaggle/kaggle.json\"):\n",
        "    files.upload()\n",
        "    !mkdir -p ~/.kaggle && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download the HAM10000 dataset\n",
        "!kaggle datasets download -d kmader/skin-cancer-mnist-ham10000\n",
        "!unzip -q skin-cancer-mnist-ham10000.zip\n",
        "\n",
        "# --- STEP B: THE PYTORCH PIPELINE ---\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 1. Preprocessing (Medical Imaging Standard)\n",
        "# We resize to 224x224 and use the 'ImageNet' mean/std for normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 2. Transfer Learning: Load ResNet50\n",
        "# We use the pre-trained 'weights' from ImageNet\n",
        "model = models.resnet50(weights='DEFAULT')\n",
        "\n",
        "# Freeze all layers except the final decision layer\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Re-wire for 7 types of skin lesions (Melanoma, Nevi, etc.)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 7)\n",
        "\n",
        "# --- STEP C: THE PREDICTION FUNCTION ---\n",
        "from PIL import Image\n",
        "\n",
        "def predict_skin_lesion(image_path):\n",
        "    model.eval()\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    img_t = transform(img).unsqueeze(0) # Prepare for the brain\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(img_t)\n",
        "        prediction = torch.argmax(output).item()\n",
        "\n",
        "    classes = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC']\n",
        "    print(f\"AI Diagnostic Result: {classes[prediction]}\")\n",
        "\n",
        "print(\"Pipeline Ready! You can now train on the folders or upload a test image.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload an image for skin check"
      ],
      "metadata": {
        "id": "FfQmB575tHTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. TRIGGER THE UPLOAD\n",
        "print(\"Please upload a photo of a skin lesion (.jpg or .png):\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    # 2. RUN PREDICTION\n",
        "    # This calls the function we defined in the previous step\n",
        "    model.eval()\n",
        "    img = Image.open(filename).convert('RGB')\n",
        "\n",
        "    # Preprocess the image for the model\n",
        "    img_t = transform(img).unsqueeze(0)\n",
        "\n",
        "    # Move to GPU if available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    img_t = img_t.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(img_t)\n",
        "        # Apply softmax to get probabilities\n",
        "        probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "        prediction = torch.argmax(probabilities).item()\n",
        "        confidence = probabilities[prediction].item() * 100\n",
        "\n",
        "    # 3. SHOW THE RESULTS\n",
        "    classes = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC']\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"AI Prediction: {classes[prediction]} ({confidence:.2f}% Confidence)\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Diagnostic Code: {classes[prediction]}\")\n",
        "    print(f\"Confidence: {confidence:.2f}%\")"
      ],
      "metadata": {
        "id": "NoAUYrkOtLrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can train the model even more now to get better accuracy"
      ],
      "metadata": {
        "id": "HexnMzs-v4Vc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To start we run the train loader:\n",
        "Context\n",
        "the \"Conveyor Belt\" that feeds images to your brain hasn't been built yet.\n",
        "To fix this, we need to create the train_loader. However, the HAM10000 dataset is famously \"messy\"â€”the images are stored in two separate zip folders, and the labels are in a CSV file. You can't just point the model at the images; you have to organize them first so PyTorch understands which image is a mole and which is cancer."
      ],
      "metadata": {
        "id": "l90KaG6Bv56v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Model Training"
      ],
      "metadata": {
        "id": "RPh1AU1sYDWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 1. ORGANIZE THE FILES (The HAM10000 \"Secret Sauce\")\n",
        "# PyTorch's ImageFolder needs files to be in folders named after their class\n",
        "metadata = pd.read_csv(\"HAM10000_metadata.csv\")\n",
        "base_dir = 'organized_skin_data'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Create sub-folders for each of the 7 classes\n",
        "classes = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
        "for cls in classes:\n",
        "    os.makedirs(os.path.join(base_dir, cls), exist_ok=True)\n",
        "\n",
        "# Copy images into their respective class folders\n",
        "# Note: HAM10000 images are usually in two folders: part_1 and part_2\n",
        "image_folders = ['HAM10000_images_part_1', 'HAM10000_images_part_2']\n",
        "for folder in image_folders:\n",
        "    if os.path.exists(folder):\n",
        "        for img_name in os.listdir(folder):\n",
        "            img_id = img_name.split('.')[0]\n",
        "            # Find the label for this specific image ID\n",
        "            label = metadata.loc[metadata['image_id'] == img_id, 'dx'].values[0]\n",
        "            shutil.copy(os.path.join(folder, img_name), os.path.join(base_dir, label, img_name))\n",
        "\n",
        "# 2. DEFINE THE TRAIN_LOADER\n",
        "# This is what your error was missing!\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the newly organized folder as a PyTorch Dataset\n",
        "full_dataset = datasets.ImageFolder(root=base_dir, transform=transform)\n",
        "\n",
        "# Create the iterable DataLoader\n",
        "# batch_size=32 means the \"Conveyor Belt\" delivers 32 images at a time\n",
        "train_loader = DataLoader(full_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Define the 'device' so the model knows to use the GPU\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Train Loader is now defined and images are organized!\")"
      ],
      "metadata": {
        "id": "Y5WEYgb4wQBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next is the optimizer:\n",
        "we haven't yet introduced the \"Teacher\" (optimizer) or the \"Scoring System\" (criterion) to this specific part of the code.\n",
        "**In PyTorch, the Optimizer is the mathematical engine that performs the Calculus for you**. It looks at the errors and decides exactly how much to nudge each weight in the neural network to improve the next guess."
      ],
      "metadata": {
        "id": "_UDV-3FBw2Ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# 1. THE SCORING SYSTEM (Loss Function)\n",
        "# CrossEntropyLoss is the gold standard for classification.\n",
        "# It measures the \"distance\" between the AI's probability and the truth.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 2. THE TEACHER (Optimizer)\n",
        "# 'Adam' is a very popular optimizer because it automatically adjusts the\n",
        "# learning rate as it goes.\n",
        "# We only pass 'model.fc.parameters()' because we are only training\n",
        "# the new final layer we added.\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "\n",
        "# 3. MOVE MODEL TO DEVICE\n",
        "# This ensures your model is sitting on the GPU so it can handle the math.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(\"Optimizer and Criterion are ready! You can now run the Training Loop.\")"
      ],
      "metadata": {
        "id": "QjBIrekgxBbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we run the training:"
      ],
      "metadata": {
        "id": "EKjk4EdAwS4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- THE \"BRAIN\" TRAINING LOOP ---\n",
        "num_epochs = 5  # Start with 5 'laps' through the data\n",
        "model.train()   # Put the model in learning mode\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        # Move data to the GPU (if available) for 10x speed\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # 1. Clear previous errors (Gradients)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 2. Forward Pass: Make a guess\n",
        "        outputs = model(images)\n",
        "\n",
        "        # 3. Calculate the \"Penalty\" (Loss)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 4. BACKPROPAGATION: The Calculus Step!\n",
        "        # This finds out which weights to blame for the loss\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Step: The Optimizer nudges the weights to be better\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} finished. Error level: {running_loss/len(train_loader):.4f}\")"
      ],
      "metadata": {
        "id": "RmsoIRoQv78b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's save the \"brain\" so no need to retrain.\n",
        "Save the modelâ€™s weights to a file in your Google Drive so you can \"load\" them instantly without re-training"
      ],
      "metadata": {
        "id": "4MNVdMsV21sA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the 'State Dict' (the actual weights) of your model\n",
        "torch.save(model.state_dict(), 'skin_cancer_model.pth')\n",
        "print(\"Model weights saved! Download this file to keep your 'trained' brain.\")"
      ],
      "metadata": {
        "id": "90fMJyR42_2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Congratulations!! You know have an Ai that can identify different types of Skin Cancers! ðŸ§‘"
      ],
      "metadata": {
        "id": "AwPK3vPQYe0i"
      }
    }
  ]
}